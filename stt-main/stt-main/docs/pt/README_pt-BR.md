<div align="center">

[‰∏≠ÊñáÁÆÄ‰Ωì](../../README.md) | [English](../en/README_EN.md) | **Portugu√™s (Brasil)**

</div>

---

<div align="center">

[üëë Apoie o projeto](https://github.com/jianchang512/pyvideotrans/blob/main/docs/pt-BR/About_pt-BR.md) | [Discord](https://discord.gg/SyT6GEwkJS)

</div>

---


# Ferramenta de Transcri√ß√£o de Fala para Texto (stt)

Transcreva localmente seus √°udios e v√≠deos com esta ferramenta offline. Baseada no modelo open source fast-whisper, ela converte a fala humana em texto, exportando em formatos json, srt com timestamps e texto puro. Ap√≥s implantada, substitui com precis√£o similar servi√ßos de reconhecimento de fala online como OpenAI ou Baidu.

**Recursos:**

* **Totalmente offline:** Implante em redes internas.
* **Modelos flex√≠veis:** O fast-whisper oferece vers√µes base/small/medium/large-v3. A qualidade aumenta do base para large-v3, mas exige mais recursos. Baixe e descompacte outros modelos na pasta `models`.
* **Acelera√ß√£o CUDA:** Se tiver uma GPU Nvidia e o ambiente CUDA configurado, use a acelera√ß√£o CUDA automaticamente.

## üì¢ **Patrocinador**

[![](https://github.com/user-attachments/assets/48f4ac8f-e321-4bd3-ab2e-d6053d932f49)](https://302.ai/)

**302.AI: A Plataforma de IA Sob Demanda**

A 302.AI √© a plataforma que re√∫ne as melhores IAs do mundo em um s√≥ lugar, com pagamento sob demanda e sem mensalidades. Experimente diversas ferramentas de IA sem barreiras de entrada!

**Benef√≠cios:**

* **Funcionalidades completas:** Chat de IA, gera√ß√£o de imagens e v√≠deos, processamento de imagens e muito mais.
* **F√°cil de usar:** Rob√¥s, ferramentas e APIs para atender a todos os n√≠veis de usu√°rio.
* **Pagamento sob demanda:** Sem planos mensais, sem barreiras para produtos, pague apenas pelo que usar. Seu saldo nunca expira!
* **Separa√ß√£o de administradores e usu√°rios:** Especialistas em IA configuram tudo para voc√™, simplificando o uso.

**üéÅ B√¥nus Exclusivo:**

**[Clique para se registrar](https://302.ai)** e ganhe 1 PTC (1 PTC = 1 d√≥lar americano, cerca de 7 yuans) imediatamente. Al√©m disso, ganhe 5 PTC por dia experimentando a plataforma atrav√©s do link.

**Junte-se √† 302.AI e explore o mundo da intelig√™ncia artificial sem limites!**


## Demonstra√ß√£o

https://github.com/jianchang512/stt/assets/3378335/d716acb6-c20c-4174-9620-f574a7ff095d

![Imagem de demonstra√ß√£o](https://github.com/jianchang512/stt/assets/3378335/0f724ff1-21b3-4960-b6ba-5aa994ea414c)


# Como Usar a Vers√£o Pr√©-compilada (Windows) e Implantar o C√≥digo Fonte (Linux, Mac e Windows)

## Vers√£o Pr√©-compilada (Windows)

1. **Baixe os arquivos:** Acesse a [p√°gina de lan√ßamentos](https://github.com/jianchang512/stt/releases) e baixe os arquivos pr√©-compilados.
2. **Descompacte:** Extraia os arquivos em um local de sua prefer√™ncia (ex: `E:/stt`).
3. **Execute:** D√™ um duplo clique em `start.exe` e aguarde a abertura autom√°tica da janela do navegador.
4. **Utilize a interface:**
    * Clique na √°rea de upload da p√°gina.
    * Selecione o arquivo de √°udio ou v√≠deo desejado (ou arraste-o para a √°rea).
    * Escolha o idioma da fala, o formato de sa√≠da do texto e o modelo.
    * Clique em "Iniciar Reconhecimento".
    * O resultado ser√° exibido na caixa de texto inferior no formato escolhido.
5. **Acelera√ß√£o CUDA (opcional):** Se o seu computador possui uma GPU Nvidia e o ambiente CUDA est√° configurado corretamente, a acelera√ß√£o CUDA ser√° utilizada automaticamente.

## Implanta√ß√£o do C√≥digo Fonte (Linux, Mac e Windows)

**Requisitos:**

* Python 3.9, 3.10 ou 3.11

**Passos:**

1. **Crie um diret√≥rio:** Crie um diret√≥rio vazio (ex: `E:/stt`).
2. **Clone o reposit√≥rio:** Abra o terminal (ou prompt de comando) neste diret√≥rio e execute:
   ```bash
   git clone https://github.com/jianchang512/stt.git
   ```
3. **Crie um ambiente virtual:**
   ```bash
   python -m venv venv
   ```
4. **Ative o ambiente virtual:**
   * **Windows:** `%cd%/venv/scripts/activate`
   * **Linux/Mac:** `source ./venv/bin/activate`
5. **Instale as depend√™ncias:**
   ```bash
   pip install -r requirements.txt
   ```
   * Em caso de erro de conflito de vers√£o, execute:
     ```bash
     pip install -r requirements.txt --no-deps
     ```
   * Para suporte √† acelera√ß√£o CUDA:
     ```bash
     pip uninstall -y torch
     pip install torch --index-url [https://download.pytorch.org/whl/cu121](https://download.pytorch.org/whl/cu121)
     ```
6. **Instale o FFmpeg:**
   * **Windows:** Descompacte `ffmpeg.7z` e coloque `ffmpeg.exe` e `ffprobe.exe` no diret√≥rio do projeto.
   * **Linux/Mac:** Consulte as instru√ß√µes de instala√ß√£o do FFmpeg para sua distribui√ß√£o.
7. **Baixe os modelos:**
    * **M√©todo 01:**
        Baixe o [pacote de modelos compactado](https://github.com/jianchang512/stt/releases/tag/0.0) e coloque as pastas descompactadas na pasta `models` no diret√≥rio raiz do projeto.
    * **M√©todo 02:**
        Use esta [tabela de modelos fast-whisper](https://github.com/jianchang512/pyvideotrans/blob/main/docs/pt-BR/Download-do-Modelo.md#modelos-faster-whisper) para baixar os modelos diretamente.
8.  **Execute:**
   ```bash
   python start.py
   ```
   Aguarde a abertura autom√°tica da janela do navegador.

# Interface da API

* **Endere√ßo:** `http://127.0.0.1:9977/api`
* **M√©todo:** POST
* **Par√¢metros:**
    * `language` (c√≥digo do idioma):
        * Chin√™s: `zh`
        * Ingl√™s: `en`
        * Franc√™s: `fr`
        * Alem√£o: `de`
        * Japon√™s: `ja`
        * Coreano: `ko`
        * Russo: `ru`
        * Espanhol: `es`
        * Tailand√™s: `th`
        * Italiano: `it`
        * Portugu√™s: `pt`
        * Vietnamita: `vi`
        * √Årabe: `ar`
        * Turco: `tr`
    * `model` (nome do modelo):
        * `base`: corresponde a `models/models--Systran--faster-whisper-base`
        * `small`: corresponde a `models/models--Systran--faster-whisper-small`
        * `medium`: corresponde a `models/models--Systran--faster-whisper-medium`
        * `large-v3`: corresponde a `models/models--Systran--faster-whisper-large-v3`
    * `response_format` (formato de legenda): `text`, `json` ou `srt`
    * `file` (arquivo de √°udio ou v√≠deo)

**Exemplo de Requisi√ß√£o (Python):**

```python
import requests

# Endere√ßo da API
url = "http://127.0.0.1:9977/api"

# Par√¢metros da requisi√ß√£o
files = {"file": open("C:/Users/c1/Videos/2.wav", "rb")}
data = {"language": "zh", "model": "base", "response_format": "json"}

# Faz a requisi√ß√£o POST
response = requests.post(url, timeout=600, data=data, files=files)

# Imprime a resposta em formato JSON
print(response.json())

# Interpreta√ß√£o da resposta:
# - code == 0: sucesso
# - code != 0: falha
# - msg == "sucesso": reconhecimento bem-sucedido
# - msg != "sucesso": motivo da falha
# - data: texto retornado ap√≥s o reconhecimento (se houver)
```

## Suporte √† Acelera√ß√£o CUDA

**Instala√ß√£o de Ferramentas CUDA:** Para detalhes sobre o processo de instala√ß√£o, consulte este [guia detalhado](https://juejin.cn/post/7318704408727519270).

Se o seu computador possui uma placa gr√°fica Nvidia, siga estes passos:

1. **Atualize o driver da placa gr√°fica** para a vers√£o mais recente.
2. **Instale o CUDA Toolkit** e o **cudnn for CUDA11.x** correspondentes:
    * [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
    * [cudnn for CUDA11.x](https://developer.nvidia.com/rdp/cudnn-archive)
3. **Verifique a instala√ß√£o:**
    * Pressione `Win + R`, digite `cmd` e pressione Enter.
    * Na janela de comando, digite `nvcc --version` e confirme se as informa√ß√µes da vers√£o s√£o exibidas (similar √† imagem abaixo).
![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/e68de07f-4bb1-4fc9-bccd-8f841825915a)
    * Digite `nvidia-smi` e verifique se as informa√ß√µes de sa√≠da incluem o n√∫mero da vers√£o CUDA (similar √† imagem abaixo).
    * Execute `python testcuda.py`. Se exibir uma mensagem de sucesso, a instala√ß√£o est√° correta. Caso contr√°rio, revise e reinstale cuidadosamente.
![image](https://github.com/jianchang512/pyvideotrans/assets/3378335/71f1d7d3-07f9-4579-b310-39284734006b)

**Habilitando a Acelera√ß√£o CUDA:**

Por padr√£o, a CPU √© usada para c√°lculos. Se voc√™ confirmou que est√° usando uma placa gr√°fica Nvidia e o ambiente CUDA est√° configurado corretamente, altere `devtype=cpu` para `devtype=cuda` no arquivo `set.ini` e reinicie o programa para utilizar a acelera√ß√£o CUDA.

## Observa√ß√µes Importantes

1. **Modelos e Requisitos:** Se voc√™ n√£o possui uma placa gr√°fica Nvidia ou o ambiente CUDA n√£o est√° configurado corretamente, evite usar os modelos large/large-v3, pois eles podem consumir muita mem√≥ria e travar o sistema.
2. **Exibi√ß√£o de Caracteres:** Em alguns casos, o texto em chin√™s pode ser exibido em caracteres tradicionais.
3. **Erro "cublasxx.dll n√£o existe":** Baixe o cuBLAS neste link: [cuBLAS Download](https://github.com/jianchang512/stt/releases/download/0.0/cuBLAS_win.7z). Descompacte o arquivo e copie os arquivos DLL para `C:/Windows/System32`.
4. **Mensagem de Aviso no Console:** Se o console exibir a mensagem "[W:onnxruntime:Default, onnxruntime_pybind_state.cc:1983 onnxruntime::python::CreateInferencePybindStateModule] Init provider bridge failed.", ignore-a, pois n√£o afeta o uso do programa.
5. **Falha na Execu√ß√£o com CUDA Habilitado:**
    * **Poss√≠vel Causa:** Se o CUDA estiver habilitado, mas o cudnn n√£o foi instalado e configurado manualmente, pode ocorrer falha na execu√ß√£o.
    * **Solu√ß√£o:** Instale a vers√£o do cudnn que corresponde √† sua vers√£o do CUDA. Consulte o guia detalhado para instru√ß√µes: [Guia de Instala√ß√£o](https://juejin.cn/post/7318704408727519270).
    * **Mem√≥ria de V√≠deo Insuficiente:** Se o problema persistir ap√≥s a instala√ß√£o do cudnn, a mem√≥ria de v√≠deo da GPU pode ser insuficiente. Nesse caso, tente usar o modelo medium e evite o modelo large-v3, especialmente se a mem√≥ria de v√≠deo for inferior a 8GB e o v√≠deo tiver mais de 20MB.

Lembre-se de que este guia fornece informa√ß√µes b√°sicas e voc√™ pode precisar consultar recursos adicionais para solucionar problemas espec√≠ficos.

# Projetos Relacionados

* [Tradu√ß√£o e Dublagem de V√≠deo](https://github.com/jianchang512/pyvideotrans)
* [Clonagem de Voz](https://github.com/jianchang512/clone-voice)
* [Separa√ß√£o de Voz e M√∫sica](https://github.com/jianchang512/vocal-separate)

# Agradecimentos

Este projeto utiliza:

1. https://github.com/SYSTRAN/faster-whisper
2. https://github.com/pallets/flask
3. https://ffmpeg.org/
4. https://layui.dev
